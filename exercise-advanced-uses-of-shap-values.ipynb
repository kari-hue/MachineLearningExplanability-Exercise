{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This notebook is an exercise in the [Machine Learning Explainability](https://www.kaggle.com/learn/machine-learning-explainability) course.  You can reference the tutorial at [this link](https://www.kaggle.com/dansbecker/advanced-uses-of-shap-values).**\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"## Set Up\n\n\nWe have again provided code to do the basic loading, review and model-building. Run the cell below to set everything up:","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nimport shap\n\n# Environment Set-Up for feedback system.\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.ml_explainability.ex5 import *\nprint(\"Setup Complete\")\n\n\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\ndata = pd.read_csv('../input/hospital-readmissions/train.csv')\ny = data.readmitted\nbase_features = ['number_inpatient', 'num_medications', 'number_diagnoses', 'num_lab_procedures', \n                 'num_procedures', 'time_in_hospital', 'number_outpatient', 'number_emergency', \n                 'gender_Female', 'payer_code_?', 'medical_specialty_?', 'diag_1_428', 'diag_1_414', \n                 'diabetesMed_Yes', 'A1Cresult_None']\n\n# Some versions of shap package error when mixing bools and numerics\nX = data[base_features].astype(float)\n\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n\n# For speed, we will calculate shap values on smaller subset of the validation data\nsmall_val_X = val_X.iloc[:150]\nmy_model = RandomForestClassifier(n_estimators=30, random_state=1).fit(train_X, train_y)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T02:49:57.369166Z","iopub.execute_input":"2021-12-30T02:49:57.36962Z","iopub.status.idle":"2021-12-30T02:50:01.62362Z","shell.execute_reply.started":"2021-12-30T02:49:57.369514Z","shell.execute_reply":"2021-12-30T02:50:01.622613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"execution":{"iopub.status.busy":"2021-12-30T02:50:37.679536Z","iopub.execute_input":"2021-12-30T02:50:37.679889Z","iopub.status.idle":"2021-12-30T02:50:37.738611Z","shell.execute_reply.started":"2021-12-30T02:50:37.679856Z","shell.execute_reply":"2021-12-30T02:50:37.73775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The first few questions require examining the distribution of effects for each feature, rather than just an average effect for each feature.  Run the following cell for a summary plot of the shap_values for readmission. It will take about 20 seconds to run.","metadata":{}},{"cell_type":"code","source":"explainer = shap.TreeExplainer(my_model)\nshap_values = explainer.shap_values(small_val_X)\n\nshap.summary_plot(shap_values[1], small_val_X)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T02:50:55.278481Z","iopub.execute_input":"2021-12-30T02:50:55.279402Z","iopub.status.idle":"2021-12-30T02:51:22.199851Z","shell.execute_reply.started":"2021-12-30T02:50:55.279349Z","shell.execute_reply":"2021-12-30T02:51:22.199005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Question 1\n\nWhich of the following features has a bigger range of effects on predictions (i.e. larger difference between most positive and most negative effect)\n- `diag_1_428` or\n- `payer_code_?`","metadata":{}},{"cell_type":"code","source":"# set following variable to 'diag_1_428' or 'payer_code_?'\nfeature_with_bigger_range_of_effects = 'diag_1_428'\n\n# Check your answer\nq_1.check()","metadata":{"execution":{"iopub.status.busy":"2021-12-30T02:53:28.085392Z","iopub.execute_input":"2021-12-30T02:53:28.085714Z","iopub.status.idle":"2021-12-30T02:53:28.094889Z","shell.execute_reply.started":"2021-12-30T02:53:28.085676Z","shell.execute_reply":"2021-12-30T02:53:28.093914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Uncomment the line below to see the solution and explanation.","metadata":{}},{"cell_type":"code","source":"# q_1.solution()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Question 2\n\nDo you believe the range of effects sizes (distance between smallest effect and largest effect) is a good indication of which feature will have a higher permutation importance? Why or why not?  \n\nIf the **range of effect sizes** measures something different from **permutation importance**: which is a better answer for the question \"Which of these two features does the model say is more important for us to understand when discussing readmission risks in the population?\"\n\nRun the following line after you've decided your answer.","metadata":{}},{"cell_type":"markdown","source":"<b> Answer: </b> No, not really. Having higher range of effect size doesn't indicate that the feature has higher importance in impacting the output. From the above observation itself eventhough the diag_1_428 has wider range of effect size it seems to have lesser impact on the output than compared to payer_Codes which has smaller range of effect size. On saying that we can't also deny num_inpatient which has the higher impact on the output has very large range of effect size. So range of the feature has nothing much to tell about the importance of the feature.","metadata":{}},{"cell_type":"code","source":"# Check your answer (Run this code cell to receive credit!)\nq_2.solution()","metadata":{"execution":{"iopub.status.busy":"2021-12-30T02:59:49.01768Z","iopub.execute_input":"2021-12-30T02:59:49.01796Z","iopub.status.idle":"2021-12-30T02:59:49.024772Z","shell.execute_reply.started":"2021-12-30T02:59:49.017932Z","shell.execute_reply":"2021-12-30T02:59:49.02425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Question 3\n\nBoth `diag_1_428` and `payer_code_?` are binary variables, taking values of 0 or 1.\n\nFrom the graph, which do you think would typically have a bigger impact on predicted readmission risk:\n- Changing `diag_1_428` from 0 to 1\n- Changing `payer_code_?` from 0 to 1\n\nTo save you scrolling, we have included a cell below to plot the graph again (this one runs quickly).","metadata":{}},{"cell_type":"code","source":"shap.summary_plot(shap_values[1], small_val_X)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T03:00:09.622472Z","iopub.execute_input":"2021-12-30T03:00:09.624026Z","iopub.status.idle":"2021-12-30T03:00:10.318103Z","shell.execute_reply.started":"2021-12-30T03:00:09.623962Z","shell.execute_reply":"2021-12-30T03:00:10.317158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set following var to \"diag_1_428\" if changing it to 1 has bigger effect.  Else set it to 'payer_code_?'\nbigger_effect_when_changed = 'diag_1_428'\n\n# Check your answer\nq_3.check()","metadata":{"execution":{"iopub.status.busy":"2021-12-30T03:01:21.135589Z","iopub.execute_input":"2021-12-30T03:01:21.136873Z","iopub.status.idle":"2021-12-30T03:01:21.146003Z","shell.execute_reply.started":"2021-12-30T03:01:21.136792Z","shell.execute_reply":"2021-12-30T03:01:21.145363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For a solution and explanation, uncomment the line below.","metadata":{}},{"cell_type":"code","source":"# q_3.solution()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Question 4\n\nSome features (like `number_inpatient`) have reasonably clear separation between the blue and pink dots. Other variables like `num_lab_procedures` have blue and pink dots jumbled together, even though the SHAP values (or impacts on prediction) aren't all 0.\n\nWhat do you think you learn from the fact that `num_lab_procedures` has blue and pink dots jumbled together? Once you have your answer, run the line below to verify your solution.","metadata":{}},{"cell_type":"markdown","source":"The jumbling suggests that sometimes increasing that feature leads to higher predictions, and other times it leads to a lower prediction. Said another way, both high and low values of the feature can have both positive and negative effects on the prediction.","metadata":{}},{"cell_type":"code","source":"# Check your answer (Run this code cell to receive credit!)\nq_4.solution()","metadata":{"execution":{"iopub.status.busy":"2021-12-30T03:03:31.956014Z","iopub.execute_input":"2021-12-30T03:03:31.957165Z","iopub.status.idle":"2021-12-30T03:03:31.966647Z","shell.execute_reply.started":"2021-12-30T03:03:31.95709Z","shell.execute_reply":"2021-12-30T03:03:31.965289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Question 5\n\nConsider the following SHAP contribution dependence plot. \n\nThe x-axis shows `feature_of_interest` and the points are colored based on `other_feature`.\n\n![Imgur](https://i.imgur.com/zFdHneM.png)\n\nIs there an interaction between `feature_of_interest` and `other_feature`?  \nIf so, does `feature_of_interest` have a more positive impact on predictions when `other_feature` is high or when `other_feature` is low?\n\nRun the following code when you are ready for the answer.","metadata":{}},{"cell_type":"markdown","source":"<b> Answer :</b> Yes, we can see the interaction between feature of interest and other_feature. But the interaction is quiet strange. In some cases when the feature_of_interest value is low we can observe the low value of other_feature,while in other cases when the feature_of_interest value is high the other_feature value still remains low and viceversa. So it's kind of odd interaction. It concludes that feature_of_interest can either incerese or decrese for the high or low value of other_feature. Hence, there's no fixed pattern.","metadata":{}},{"cell_type":"code","source":"# Check your answer (Run this code cell to receive credit!)\nq_5.solution()","metadata":{"execution":{"iopub.status.busy":"2021-12-30T03:14:44.611285Z","iopub.execute_input":"2021-12-30T03:14:44.611621Z","iopub.status.idle":"2021-12-30T03:14:44.619117Z","shell.execute_reply.started":"2021-12-30T03:14:44.611588Z","shell.execute_reply":"2021-12-30T03:14:44.618534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Question 6\n\nReview the summary plot for the readmission data by running the following cell:","metadata":{}},{"cell_type":"code","source":"shap.summary_plot(shap_values[1], small_val_X)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T03:14:51.744051Z","iopub.execute_input":"2021-12-30T03:14:51.744355Z","iopub.status.idle":"2021-12-30T03:14:52.374851Z","shell.execute_reply.started":"2021-12-30T03:14:51.744321Z","shell.execute_reply":"2021-12-30T03:14:52.374039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Both **num_medications** and **num_lab_procedures** share that jumbling of pink and blue dots.\n\nAside from `num_medications` having effects of greater magnitude (both more positive and more negative), it's hard to see a meaningful difference between how these two features affect readmission risk.  Create the SHAP dependence contribution plots for each variable, and describe what you think is different between how these two variables affect predictions.\n\nAs a reminder, here is the code you previously saw to create this type of plot.\n\n    shap.dependence_plot(feature_of_interest, shap_values[1], val_X)\n    \nAnd recall that your validation data is called `small_val_X`.","metadata":{}},{"cell_type":"code","source":"# for num_medications\n\nfeature_name = 'num_medications'\n\nshap.dependence_plot(feature_name, shap_values[1], small_val_X)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T03:20:23.630486Z","iopub.execute_input":"2021-12-30T03:20:23.630842Z","iopub.status.idle":"2021-12-30T03:20:23.876395Z","shell.execute_reply.started":"2021-12-30T03:20:23.630806Z","shell.execute_reply":"2021-12-30T03:20:23.875154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then run the following line to compare your observations from this graph to the solution.","metadata":{}},{"cell_type":"code","source":"# Check your answer (Run this code cell to receive credit!)\nq_6.solution()","metadata":{"execution":{"iopub.status.busy":"2021-12-30T03:18:37.433248Z","iopub.execute_input":"2021-12-30T03:18:37.434111Z","iopub.status.idle":"2021-12-30T03:18:37.443249Z","shell.execute_reply.started":"2021-12-30T03:18:37.434063Z","shell.execute_reply":"2021-12-30T03:18:37.442351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Congratulations\n\nThat's it!  Machine learning models should not feel like black boxes any more, because you have the tools to inspect them and understand what they learn about the world. \n\nThis is an excellent skill for debugging models, building trust, and learning insights to make better decisions. These techniques have revolutionized how I do data science, and I hope they do the same for you.\n\nReal data science involves an element of exploration. I hope you find an interesting dataset to try these techniques on (Kaggle has a lot of [free datasets](https://www.kaggle.com/datasets) to try out). If you learn something interesting about the world, share your work [in this forum](https://www.kaggle.com/learn-forum/66354). I'm excited to see what you do with your new skills.","metadata":{}},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/machine-learning-explainability/discussion) to chat with other learners.*","metadata":{}}]}